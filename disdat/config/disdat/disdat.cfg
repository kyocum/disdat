[core]
# Out of the box, ignore code version.
ignore_code_version=True

[docker]
# A Docker registry to which to push pipeline images. For example:
# registry = docker.io
# If using AWS ECR, you can specify "*ECR*", and disdat will determine the
# registry for you:
# registry = *ECR*

# An optional Docker repository prefix to use before the (generated)
# pipeline image name when pushing images to a registry. Do *not* include
# the registry in the repository prefix. For example:
# repository_prefix = username/projectname

# If specified, log into ECR before pushing an image; not necessary if the
# registry is "*ECR*"
# ecr_login =

[dockerize]
os_type = python
os_version = 2.7.15-slim

# Optional pip file
#dot_pip_file = ~/.pip/pip.conf

# Optional odbc file bake-in.

# Note, you might expose a password in the docker cache / registry if they are not secured.
# AWS ECS encrypts images, but the machine on which you build the container may contain a layer in its cache.
# You have been warned.

# Also, note that your architecture might install your client DB libraries in different places than the
# Docker container (python-slim).  You will need to create a config/<your OS choice>/ directory and place
# either a deb.txt or deb packages for those client libraries to be installed.

#dot_odbc_ini_file = ~/.odbc.ini

[run]
# For AWS Batch: A job queue
aws_batch_queue = disdat-batch-queue

# For AWS SageMaker: default instance type is smallest
# other valid types include: 
#  'ml.m4.xlarge' | 'ml.m4.2xlarge' | 'ml.m4.4xlarge' | 'ml.m4.10xlarge' | 'ml.m4.16xlarge' | 'ml.m5.large' 
#| 'ml.m5.xlarge' | 'ml.m5.2xlarge' | 'ml.m5.4xlarge' | 'ml.m5.12xlarge' | 'ml.m5.24xlarge' | 'ml.c4.xlarge' 
#| 'ml.c4.2xlarge' | 'ml.c4.4xlarge' | 'ml.c4.8xlarge' | 'ml.p2.xlarge' | 'ml.p2.8xlarge' | 'ml.p2.16xlarge' 
#| 'ml.p3.2xlarge' | 'ml.p3.8xlarge' | 'ml.p3.16xlarge' | 'ml.c5.xlarge' | 'ml.c5.2xlarge' | 'ml.c5.4xlarge' 
#| 'ml.c5.9xlarge' | 'ml.c5.18xlarge'
aws_sagemaker_instance_type = ml.m4.xlarge 
aws_sagemaker_instance_count = 1
# Note if you have a lot of inputs in your s3 input uri, they have to fit here. Since 
# disdat uses other s3 paths for inputs, you can keep this small unless you're doing something special. 
aws_sagemaker_volume_sizeGB = 128
# Max run time for training job -- 5 minutes default
aws_sagemaker_max_runtime_sec = 300
# An input prefix, all objects that share this prefix show up in the container
aws_sagemaker_s3_input_uri = s3://somepath
# Disdat doesn't place models in the s3 destination bucket.   But SageMaker still needs one. 
aws_sagemaker_s3_output_uri = s3://somepath
# Role for SageMaker containers to assume to access S3, Cloud logs, etc. 
aws_sagemaker_role_arn = somearn
